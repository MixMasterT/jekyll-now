---
layout: post
title: Tic-Tac-Toe
---

## Does This Even Count as AI?

This week I was given a coding challenge to build a React Tic-Tac-Toe game
in 30 minutes. There was a bonus added to make a single-player version with
an ai opponent. Thirty minutes was a bit too short a time for me. But I
felt driven to finish the project.

I pretty much new all of the steps required to get a clickable Tic-Tac-Toe
game working in React. That was not the hard part, although I did get hung
up for a while do to a cryptic error message that I eventually realized was
caused by forgetting to pass in a specific prop that was referenced in
a lower-level component. Once I got that cleared up, it was pretty straight-forward.
But when I started to build the AI, I realized there were lots of steps to
getting it working. First, I had to give the user a selection for one or
two-player versions of the game, and then instantiate the AI player as needed.
Once I had that working, however, I had to figure out how to get the logic
working for the AI player. I knew I didn't want to break the strategy down
into a bunch of complicated if-then statements, though I am pretty confident
that such an approach could work to create an unbeatable Tic-Tac-Toe routine.

I had seen this problem before and I knew that some sort of PolyTree that
held all of the possible outcomes would be the key to making the AI work.
So, that was my first step. I hacked a very simple tree structure with basic
JavaScript objects. The root element is an object with a value property,
which is the Tic-Tac-Toe board, and a children property, each of which is
another object, just like the root element, but with value properties
that have one more square filled in on the board. I created a function
that would simply generate this tree given a particular board state by
recursively adding a given mark to every possible position, and then generating
more trees from the resulting boards. I tested this by logging the tree
to the console, and manually verified that it was doing what I expected.

Then, I figured the logic would be easy: just find a tree that has the
AI player's mark as a winner, or if no such result could be found, return
a move where the AIPlayer wasn't the loser. I already had a function built for determining
the winner that I had used for the game, so I factored that and a few other
important utility methods out into a TicTacToeModule, which I then used
in both the game and the AIPlayer class. My idea sort of worked, but after
playing against the AI player a few times, I noticed a problem. It was
over-optimistic. It made moves where it might possibly win, but was not
defensive and ignored the obvious fact that it also might lose. This was
not going to work.

So I started looking around at how other people have implemented Tic-Tac-Toe
AI. I realized that my logic was missing a further test. I would need to
return a move that was either a winning move, or put the other player (the
human opponent) into a losing position. But that became logically complicated
quickly, because the AI would need to keep switching roles and evaluating
'X' options, and then 'O' options in turn. Instead, I decided to follow
a different approach, called MiniMax. This is based on giving a weight
to each possible outcome. To make this work, I wrote a function called
getTreeScore, that I could pass an outcomesTree into, and it would return a
score based on how many outcomes in that tree were wins, and how many were
losses. Wins were worth plus points and losses were worth minus points.
This worked a bit better, but I was still able to beat the AI.

To try and figure out what was going on, I logged out the scores for the trees
generated by each possible move, and saw that man of the trees had the same
score. I realized then that the problem had to do with depth. This made good
sense because winning on the next move is better than maybe winning after
four more moves, but the score wasn't really reflecting that. So, how could
I make it so that more deeply nested wins (or losses) would be weighted less
heavily than immediate ones?

The way I made this work was to factor out
a scoreFactor parameter, that would be passed in with the tree at the time
of calling the getTreeScore function. Since getTreeScore is implemented
recursively, I just passed in the scoreFactor divided by two. This improved
the AIPlayer's performance, but after a few tries, I was still able to beat
it. I wasn't sure what was going on, but as an experiment, I bumped up the
divisor, and passed in scoreFactor divided by ten to the recursive calls.
That seemed to do it. Since then, I have been unable to beat the Tic-Tac-Toe
AIPlayer!
